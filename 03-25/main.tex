
\documentclass[a4paper,11pt]{article}
\usepackage[a4paper, margin=8em]{geometry}

% usa i pacchetti per la scrittura in italiano
\usepackage[french,italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\frenchspacing 

% usa i pacchetti per la formattazione matematica
\usepackage{amsmath, amssymb, amsthm, amsfonts}

% usa altri pacchetti
\usepackage{gensymb}
\usepackage{hyperref}
\usepackage{standalone}

% imposta il titolo
\title{Appunti Fondamenti di Automatica}
\author{Luca Seggiani}
\date{2025}

% disegni
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}

% imposta lo stile
% usa helvetica
\usepackage[scaled]{helvet}
% usa palatino
\usepackage{palatino}
% usa un font monospazio guardabile
\usepackage{lmodern}

% tikz in sans
\tikzset{every picture/.style={/utils/exec={\sffamily}}}

\renewcommand{\rmdefault}{ppl}
\renewcommand{\sfdefault}{phv}
\renewcommand{\ttdefault}{lmtt}

% circuiti
\usepackage{circuitikz}
\usetikzlibrary{babel}

% disponi il titolo
\makeatletter
\renewcommand{\maketitle} {
	\begin{center} 
		\begin{minipage}[t]{.8\textwidth}
			\textsf{\huge\bfseries \@title} 
		\end{minipage}%
		\begin{minipage}[t]{.2\textwidth}
			\raggedleft \vspace{-1.65em}
			\textsf{\small \@author} \vfill
			\textsf{\small \@date}
		\end{minipage}
		\par
	\end{center}

	\thispagestyle{empty}
	\pagestyle{fancy}
}
\makeatother

% disponi teoremi
\usepackage{tcolorbox}
\newtcolorbox[auto counter, number within=section]{theorem}[2][]{%
	colback=blue!10, 
	colframe=blue!40!black, 
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries, 
	title=Teorema~\thetcbcounter: #2, 
	#1
}

% disponi definizioni
\newtcolorbox[auto counter, number within=section]{definition}[2][]{%
	colback=red!10,
	colframe=red!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Definizione~\thetcbcounter: #2,
	#1
}

% disponi problemi
\newtcolorbox[auto counter, number within=section]{problem}[2][]{%
	colback=green!10,
	colframe=green!40!black,
	sharp corners=northwest,
	fonttitle=\sffamily\bfseries,
	title=Problema~\thetcbcounter: #2,
	#1
}

% disponi codice
\usepackage{listings}
\usepackage[table]{xcolor}

\lstdefinestyle{codestyle}{
		backgroundcolor=\color{black!5}, 
		commentstyle=\color{codegreen},
		keywordstyle=\bfseries\color{magenta},
		numberstyle=\sffamily\tiny\color{black!60},
		stringstyle=\color{green!50!black},
		basicstyle=\ttfamily\footnotesize,
		breakatwhitespace=false,         
		breaklines=true,                 
		captionpos=b,                    
		keepspaces=true,                 
		numbers=left,                    
		numbersep=5pt,                  
		showspaces=false,                
		showstringspaces=false,
		showtabs=false,                  
		tabsize=2
}

\lstdefinestyle{shellstyle}{
		backgroundcolor=\color{black!5}, 
		basicstyle=\ttfamily\footnotesize\color{black}, 
		commentstyle=\color{black}, 
		keywordstyle=\color{black},
		numberstyle=\color{black!5},
		stringstyle=\color{black}, 
		showspaces=false,
		showstringspaces=false, 
		showtabs=false, 
		tabsize=2, 
		numbers=none, 
		breaklines=true
}

\lstdefinelanguage{javascript}{
	keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
	keywordstyle=\color{blue}\bfseries,
	ndkeywords={class, export, boolean, throw, implements, import, this},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{purple}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

% disponi sezioni
\usepackage{titlesec}

\titleformat{\section}
	{\sffamily\Large\bfseries} 
	{\thesection}{1em}{} 
\titleformat{\subsection}
	{\sffamily\large\bfseries}   
	{\thesubsection}{1em}{} 
\titleformat{\subsubsection}
	{\sffamily\normalsize\bfseries} 
	{\thesubsubsection}{1em}{}

% disponi alberi
\usepackage{forest}

\forestset{
	rectstyle/.style={
		for tree={rectangle,draw,font=\large\sffamily}
	},
	roundstyle/.style={
		for tree={circle,draw,font=\large}
	}
}

% disponi algoritmi
\usepackage{algorithm}
\usepackage{algorithmic}
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\makeatother

% disponi numeri di pagina
\usepackage{fancyhdr}
\fancyhf{} 
\fancyfoot[L]{\sffamily{\thepage}}

\makeatletter
\fancyhead[L]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@title \ \@date}}} 
\fancyhead[R]{\raisebox{1ex}[0pt][0pt]{\sffamily{\@author}}}
\makeatother

\begin{document}

% sezione (data)
\section{Lezione del 25-03-25}

% stili pagina
\thispagestyle{empty}
\pagestyle{fancy}

% testo
Proseguiamo con la discussione delle proprietà della trasformata di Laplace.

\subsubsection{Teorema del valor iniziale}
Un utile teorema per il calcolo del valore iniziale di una funzione a partire dal suo sviluppo di Taylor è il seguente:
\begin{theorem}{Teorema del valor iniziale}
	Per una funzione $g$ con trasformata di Laplace $G$ vale:
	$$
	\lim_{t \rightarrow 0} f(t) = \lim_{s \rightarrow \infty} (s \cdot G(s))
	$$
\end{theorem}

Conosciamo l'espansione di Taylor di una funzione:
$$
f(t) = f(t_0) + f'(t_0) (t - t_0) + ... + \frac{f^{(k)}(t_0)}{k!}(t - t_0)^k
$$
che con $t = 0$ dà:
$$
f(t) = f(t_0) + f' (t_0) t + ... + \frac{f^{(k)}(t_0)}{k!}t^k
$$

Notiamo di aver già calcolato la trasformata di Laplace dei i vari $\frac{t^k}{k!}$ come (sezione 10.1, proprietà 4):
$$
\mathcal{L} \left\{ \frac{t^k}{k!} \cdot H(t) \right\} = \frac{1}{s^{k + 1}}
$$
e quindi:
$$
G(s) = f(t_0) \frac{1}{s} + f'(t_0) \frac{1}{s^2} ... + f^{(k)}(t_0) \frac{1}{s^{k + 1}}
$$

Preso $s \cdot G(s)$:
$$
s \cdot G(s) = f(t_0) + f'(t_0) \frac{1}{s^1} ... + f^{(k)}(t_0) \frac{1}{s^k}
$$
varrà allora che:
$$
\lim_{t \rightarrow 0} f(t) = \lim_{s \rightarrow \infty} (s \cdot G(s))
$$
in quanto solo il termine a coefficiente $f(t_0)$ non decade a 0. \qed

Questo è uno dei cosiddetti \textbf{legami globali} fra la funzione $f$ e la sua trasformata di Laplace $F$. 
Possiamo sfruttare questo legame per avere informazioni riguardo al valore iniziale di $f$: basterà prendere il limite di $s \cdot G(s)$ ad infinito.

\subsubsection{Teorema del valor finale}
Possiamo ricavare un risultato simile per il valore finale semplicemente scambiando i punti di limite:
\begin{theorem}{Teorema del valor finale}
	Per una funzione $f$ con trasformata di Laplace $G$ vale:
	$$
	\lim_{t \rightarrow \infty} f(t) = \lim_{s \rightarrow 0} (s \cdot G(s))
	$$
\end{theorem}
Con condizione di validità che $\lim_{t \rightarrow \infty} f(t)$ esista finito. 

Possiamo dimostrare il risultato partendo dalla trasformata di Laplace della derivata di $f$, cioè:
$$
\mathcal{L}\left\{ \frac{d}{dt}f(t) \right\} = \int_0^{+\infty} \frac{df}{dt}(t) \cdot e^{-st} \, dt = sG(s) - f(0)
$$
Prendendo il limite per $s \rightarrow 0$, si ha:
$$
\lim_{s \rightarrow 0} \left[ \int_0^{+\infty} \frac{d}{dt}f(t) \cdot e^{-st} \, dt \right] = \lim_{s \rightarrow 0} \left[ sG(s) - f(0) \right] 
$$
e visto che:
$$
\lim_{s \rightarrow 0} \left[ \int_0^{+\infty} \frac{d}{dt}f(t) \cdot e^{-st} \, dt \right] = \lim_{s \rightarrow 0} \left[ \int_0^{+\infty} \frac{d}{dt} f(t) \right] = \lim_{s \rightarrow 0} \left[ f(t) - f(0) \right]
$$
si ha:
$$
\lim_{t \rightarrow \infty} \left[ f(t) - f(0) \right] = \lim_{s \rightarrow 0} \left[ sG(s) - f(0) \right] 
\implies 
\lim_{t \rightarrow \infty} f(t) = \lim_{s \rightarrow 0} sG(s) 
$$
che è la tesi. \qed

\subsection{Scomposizione in fratti semplici}
Vediamo la parte di teoria che ci facilita l'antitrasformazione delle trasformate di Laplace.

\subsubsection{Rapporti di polinomi}
La maggior parte delle trasformate di Laplace che incontreremo non sono altro che rapporti di polinomi in forma:
$$
G(s) = \frac{N(s)}{D(s)} = \frac{N(s)}{(s - s_1)^h (s - s_1)^{h - 1} ... (s - s_1) + R(s)}
$$
presi i poli in $s_1$, dove gli $(s - s_1)^{h - i + 1}$ sono gli $h$ poli di molteplicità $h - i + 1$ in $s_1$, e $R(s)$ rappresenta tutti gli altri poli.

Si potrà allora riscrivere $G(s)$ come la somma dei residui polari:
$$
G(s) = \frac{k_1}{(s - s_1)^h} + \frac{k_2}{(s - s_1)^{h - 1}} ... + \frac{k_h}{(s - s_1)} + T(s)
$$
dove $T(s)$ rappresenta i residui polari dei poli in $R(s)$.
La speranza è che i singoli termini $\frac{k_i}{(s - s_1)^{h - i + 1}}$ siano facili da antitrasformare (speranza solitamente sodisfatta, visto che danno componenti esponenziali o oscillatorie).

\subsubsection{Teorema dei residui}
Un risultato particolarmente utile per il calcolo dei $k_i$ è il \textbf{teorema dei residui} per poli multipli di molteplicità $i$.
\begin{theorem}{Teorema dei residui}
Il coefficiente del fratto semplice di molteplicità $h - i + 1$ associato al polo $s_1$ della trasformata $G(s)$ è:	
$$
k_i = \lim_{s \rightarrow s_1} \frac{1}{(i - 1)!} \frac{d^{(i - 1)} (s - s_1)^h \cdot G(s) }{ds^{(i - 1)}}
$$
\end{theorem}

Riprendendo l'ultima formula dello scorso paragrafo, moltiplicando a sinistra e a destra per $(s - s_1)^h$ si ottiene:
$$
(s - s_1)^h \cdot G(s) = k_1 + k_2 (s - s_1) + ... k_h (s - s_1)^{h - 1} + T(s) (s - s_1)^h 
$$
Prendendo il limite per $s \rightarrow s_1$ si ottiene:
$$
\lim_{s \rightarrow s_1} \left( (s - s_1)^h \cdot G(s) \right) = k_1
$$
Derivando nuovamente si ottiene $k_2$:
$$
\lim_{s \rightarrow s_1} \frac{d}{ds} (s - s_1)^h \cdot G(s) = k_2 + ... + k_h (h - 1) (s - s_1)^{h - 2} + h T(s) (s - s_1)^{h - 1} = k_2
$$
Continuando ad iterare si ottiene quindi:
$$
k_i = \lim_{s \rightarrow s_1} \frac{1}{(i - 1)!} \frac{d^{(i - 1)} (s - s_1)^h \cdot G(s) }{ds^{(i - 1)}}
$$
che è la tesi. \qed

\subsubsection{Esempio: scomposizione con poli multipli}
Vediamo un esempio pratico di applicazione.
Prendiamo la $G(s)$:
$$
G(s) = \frac{s + 2}{(s + 3) \cdot (s + 1)^3} = \frac{A}{s + 3} + \frac{B}{s + 1} + \frac{C}{(s + 1)^2} + \frac{D}{(s + 1)^3}
$$

Dal punto di vista dell'automatica, se prendessimo questo $G(s)$ come l'uscita $Y(s)$, staremmo effettivamente prendendo la risposta all'impulso $\delta(t)$ in dominio tempo (ricordiamo che $\delta(t)$ trasforma a 1).

Troviamo quindi i coefficienti dei fratti semplici sfruttando il teorema dei residui:
$$
A = \lim_{s \rightarrow -3} (s + 3) \cdot G(s) = \lim_{s \rightarrow -3} \frac{s + 2}{(s + 1)^3} = \frac{1}{8}
$$
$$
D = \lim_{s \rightarrow -1} (s + 1)^3 \cdot G(s) = \lim_{s \rightarrow -1} \frac{s + 2}{s + 3} = \frac{1}{2} 
$$
$$
C = \lim_{s \rightarrow -1} \frac{d}{ds} (s + 1)^2 \cdot G(s) = \lim_{s \rightarrow -1} \frac{(s + 3) - (s + 2)}{(s + 3)^2} = \frac{1}{4}
$$

Per la $B$, effettuiamo semplicemente la somma:
$$
G(s) = \frac{A(s + 1)^3 + B(s + 3)(s + 1)^2 + C(s + 1)(s + 3) + D(s+3)}{(s + 3)(s + 1)^3} = \frac{s + 2}{(s + 3)(s + 1)^3}
$$
Notiamo che gli unici termini che moltiplicano un $s^3$ saranno $A$ e $B$, e che un termine $s^3$ non compare a destra, quindi dovrà essere:
$$
A + B = 0 \implies A = -B
$$
e quindi:
$$
B = -A = -\frac{1}{8}
$$

Possiamo quindi riscrivere la $G(s)$ come:
$$
G(s) = \frac{1}{8(s + 3)} - \frac{1}{8(s + 1)} + \frac{1}{4(s + 1)^2} + \frac{1}{2(s + 1)^3}
$$
da cui l'antitrasformata:
$$
g(t) = \frac{1}{8}e^{-3t} -\frac{1}{8}e^{-t} + \frac{1}{4} t e^{-t} + \frac{1}{4} t^2 e^{-t}
$$
ricordando che $\mathcal{L}\left\{ \frac{1}{s^k} \right\} = \frac{t^{k - 1}}{k!}$, e quindi dal $k \geq 2$ in poi compaiono termini fattoriali (come ad esempio nel termine di molteplicità 3 di questo esempio).

\subsubsection{Esempio: scomposizione con poli complessi coniugati}
Vediamo un altro esempio, con la $G(s)$:
$$
G(s) = \frac{1}{(s^2 + 1)^2} = \frac{1}{(s + j)^2 (s - j)^2} = \frac{A}{s + j}+ \frac{A^*}{s - j} + \frac{B}{(s + j)^2} + \frac{B^*}{(s - j)^2}
$$
dove notiamo che \textit{i coniugati dei residui sono i residui dei coniugati}.
Quest'ultima affermazione merita un attimo di discussione.
Riducendoci al caso $i = h$ (i casi a molteplicità diversa non modificano la situazione in quanto aggiungono solo termini non complessi) si può definire la funzione residuo $\mathrm{Res}$:
$$
\mathrm{Res}(G, s_1) = \lim_{s \rightarrow s_1} (s - s_1) \cdot G(s)
$$
il coniugato di questa sarà:
$$
\left( \mathrm{Res}(G, s_1) \right)^* = \left( \lim_{s \rightarrow s_1} (s - s_1) \cdot G(s) \right)^* = \lim_{s \rightarrow s_1} (s - s_1)^* G^*(s)
$$
$$
= \lim_{s \rightarrow s_1} (s^* - s_1^*) G(s^*) = \lim_{s \rightarrow s_1*} (s - s_1^*) G(s) 
$$
fatta l'ipotesi (non banale):
$$
G(s^*) = G^*(s)
$$
Fortunatamente, se rispetta alcune (larghe) ipotesi, $G$ rispetta tale condizione.
Ci possiamo quindi accorgere che quello che abbiamo trovato non è altro che il residuo in $s_1^*$, cioè:
$$
\mathrm{Res}(G, s_1^*) = \lim_{s \rightarrow s_1^*} (s - s_1^*) \cdot G(s)
$$
da cui la tesi. \qed

\par\smallskip

Troviamo quindi i residui:
$$
A = \lim_{s \rightarrow -j} \frac{d}{ds} (s + j)^2 \cdot G(s) = \lim_{s \rightarrow -j} \frac{d}{ds} \frac{1}{(s - j)^2} = \frac{j}{4}
$$
da cui:
$$
A^* = -\frac{j}{4}
$$
e:
$$
B = \lim_{s \rightarrow -j}  (s + j)^2 \cdot G(s) = \lim_{s \rightarrow -j}  \frac{1}{(s - j)^2} = -\frac{1}{4}
$$
da cui:
$$
B^* = -\frac{1}{4}
$$

Otteniamo quindi:
$$
G(s) = \frac{j}{4(s + j)} - \frac{j}{4(s - j)} - \frac{1}{4(s + j)^2} - \frac{1}{4(s - j)^2}
$$
da cui l'antitrasformata:
$$
g(t) = \frac{j}{4} \left( e^{-jt} - e^{jt} \right) \cdot H(t) - \frac{1}{4}t \left( e^{-jt} + e^{jt} \right) \cdot H(t) = \frac{1}{2} \left( \sin(t) - t \cos(t) \right) \cdot H(t) 
$$

\subsection{Risposta all'impulso}
I sistemi LTI possono essere caratterizzati attraverso la loro risposta all'impulso, rappresentato dal delta di Dirac $\delta(t)$.
Cioè si può dire che:
$$
u(t) = \delta(t) \implies y(t) = h(t)
$$
con $h(t)$ la risposta del sistema a $\delta(t)$, ricordando lo schema:

\begin{center}
	\begin{tikzpicture}
		\draw (0,0) rectangle (2, 1);
		\draw[-stealth] (-2, 0.5) -> (0, 0.5);
		\draw[-stealth] (2, 0.5) -> (4, 0.5);
		\node at (1, 0.5) {$x(0) = 0$};
		\node at (-1, 0.8) {$u(t)$};
		\node at (3, 0.8) {$y(t)$};
	\end{tikzpicture}
\end{center}
dove si è notato stato iniziale nullo.

Notiamo che questo metodo fornisce solamente la relazione ingresso/uscita.
L'utilità sta nel fatto che la risposta all'impulso può essere usata per determinare come il sistema risponde ad altri ingressi arbitrari ($u(t)$), attraverso la convoluzione:
$$
y(t) =\int_0^t h(t - \tau) u(\tau) \, d\tau = \int_0^t h(t) u(t - \tau) \, d\tau
$$
dove $h(t)$ è sempre la risposta all'impulso di Dirac.

La motivazione di questo procedimento deriva dal fatto che possiamo interpretare la $u(t)$ in entrata come la sovrapposizione di infiniti impulsi $\delta (t - \tau)$:
$$
u(t) = \int_{-\infty}^{+\infty} u(\tau) \delta(t - \tau) \, d\tau
$$

Allora, sfruttando la linearità del sistema, possiamo interpretare l'uscita $y(t)$ come la combinazione lineare delle risposte $h(t - \tau)$ alle singole delta:
$$
y(t) = \int_{-\infty}^{+\infty} u(\tau) h(t - \tau) \, d\tau
$$
che gestendo i limiti di integrazione è esattamente quello che abbiamo detto prima. \qed

\par\smallskip

Ricordiamo quindi che nel dominio di Laplace l'integrale di convoluzione è semplice, basta infatti moltiplicare la risposta all'ingresso:
$$
Y(s) = U(s) \cdot H(s)
$$

\subsubsection{Risposta all'impulso e funzione di trasferimento}
L'antitrasformata della funzione di trasferimento rappresenta la risposta all'impulso unitario, cioè noti $Y(s)$ e $U(s)$:
$$
G(s) = \frac{Y(s)}{U(s)} \implies Y(s) = U(s) \cdot G(s)
$$
cioè esattamente la definizione di risposta all'impulso unitario.

Inoltre, vale che l'\textit{integrale} della risposta all'impulso unitario rappresenta la risposta al gradino unitario (sempre per applicazione della linearità dell'operatore integrale, che ricordiamo applicato all'impulso dà il gradino):
$$
\mathcal{L}^{-1} \left\{ \frac{G(s)}{s} \right\} = \int g(t) \, dt
$$

\subsection{Diagrammi a blocchi}
I diagrammi a blocchi sono una rappresentazione standard e uniforme di sistemi e sottosistemi interconnessi con funzioni di trasferimento.
Permettono l'identificazione di ingressi, usciti ed elementi dinamici, e quindi risultano utili concettualmente in fase di progettazione e analisi.

Nel dettaglio, studieremo 3 tipi di schemi particolari, e introdurremo la cosiddetta \textbf{algebra dei blocchi}.

\subsubsection{Connessione in serie}
La connessione in serie avviene quando più sistemi, rappresentati da una particolare funzione di trasferimento, sono connessi fra di loro ingressi ad uscite, o come si vede dal grafico:

\begin{center}
	\begin{tikzpicture}
		\draw (0,0) rectangle (2, 1);
		\draw (4,0) rectangle (6, 1);
		\draw[-stealth] (-2, 0.5) -> (0, 0.5);
		\draw[-stealth] (2, 0.5) -> (4, 0.5);
		\draw[-stealth] (6, 0.5) -> (8, 0.5);

		\node at (1, 0.5) {$G_1(s)$};
		\node at (5, 0.5) {$G_2(s)$};
		
		\node at (-1, 0.8) {$e$};
		\node at (3, 0.8) {$u$};
		\node at (7, 0.8) {$y$};
	\end{tikzpicture}
\end{center}

Avremo allora che vale:
\[
	\begin{cases}
	Y(s) = G_2(s) U(s) \\
	U(s) = G_1(s) E(s)
	\end{cases}
\]
da cui:
$$
Y(s) = G_2(s)G_1(s)E(s) \implies G(s) = G_1(s) G_2(s)
$$

Da cui il risultato generale:
\begin{theorem}{Connessione in serie}
	Sottoinsiemi con funzioni di trasferimento $G_1(s)$, $...$, $G_n(s)$ posti in serie formano un unico sistema con funzione di trasferimento:
	$$
		G_{eq}(s) = G_1(s) ... G_n(s)
	$$
\end{theorem}

\subsubsection{Connessione in parallelo}
La connessione in parallelo avviene quando più sistemi, rappresentati da una particolare funzione di trasferimento, sono connessi a un unico ingresso e un unica uscita (in un sommatore), o come si vede dal grafico:

\begin{center}
	\begin{tikzpicture}
		\draw (0,0) rectangle (2, 1);
		\draw (0,-1.5) rectangle (2, -0.5);
		\draw (0,1.5) rectangle (2, 2.5);
		
		\draw (-2, 0.5) -- (-1, 0.5);
		\draw (-1, 2) -- (-1, -1);
		\draw[-stealth] (-1, 2) -> (0, 2);
		\draw[-stealth] (-1, 0.5) -> (0, 0.5);
		\draw[-stealth] (-1, -1) -> (0, -1);

		\draw[-stealth] (3, 0.5) -> (4, 0.5);
		\draw (3, 2) -- (3, -1);
		\draw (2, 2) -> (3, 2);
		\draw (2, 0.5) -> (3, 0.5);
		\draw (2, -1) -> (3, -1);

		\node at (1, 2) {$G_1(s)$};
		\node at (1, 0.5) {$G_2(s)$};
		\node at (1, -1) {$G_3(s)$};
		
		\node at (-2, 0.8) {$e$};
		\node at (4, 0.8) {$u$};
	\end{tikzpicture}
\end{center}

In questo caso varrà:
$$
Y(s) = G_1(s)R(s) + G_2(s)R(s) + G_3(s)R(s) = \left( G_1(s) + G_2(s) + G_3(s) \right) R(s)
$$
da cui:
$$
G(s) = G_1(s) + G_2(s) + G_3(s)
$$

\begin{theorem}{Connessione in parallelo}
	Sottoinsiemi con funzioni di trasferimento $G_1(s)$, $...$, $G_n(s)$ posti in parallelo formano un unico sistema con funzione di trasferimento:
	$$
		G_{eq}(s) = G_1(s) + ... + G_n(s)
	$$
\end{theorem}

\subsubsection{Connessione in retroazione}
Vediamo un costrutto tipico dell'automatica: l'\textbf{anello di controllo}:

\begin{center}
	\begin{tikzpicture}
		\draw (0,0) rectangle (2, 1);
		\draw (0,-1.5) rectangle (2, -0.5);
			
		\draw (-2, 0.5) -- (-1, 0.5);
		\draw[stealth-] (-1, 0.4) -- (-1, -1);
		\draw[-stealth] (-1, 0.5) -> (0, 0.5);
		\draw (-1, -1) -- (0, -1);

		\draw[-stealth] (3, 0.5) -> (4, 0.5);
		\draw (3, 0.5) -- (3, -1);
		\draw (2, 0.5) -> (3, 0.5);
		\draw[stealth-] (2, -1) -> (3, -1);

		\draw[fill=white] (-1, 0.5) circle (0.1);
		\node at (-0.75, 0.75) {$+$};
		\node at (-0.75, 0.25) {$-$};

		\node at (1, 0.5) {$G_1(s)$};
		\node at (1, -1) {$G_2(s)$};
		
		\node at (-2, 0.8) {$r$};
		\node at (-0.35, 0.8) {$e$};
		\node at (3, 0.8) {$y$};
		\node at (-1.5, -0.5) {$y_m$};
		\node at (4, 0.8) {$u$};
	\end{tikzpicture}
\end{center}

Notiamo che lo schema non rappresenta altro che una descrizione matematica del modello presentato nella sezione 8.4.
In questo caso vale:
\[
	\begin{cases}	
		Y(s) = G_1(s) E(s) \\
		E(s) = R(s) - Y_m(s) \\
		Y_m(s) = G_2(s) Y(s)
	\end{cases}
\]
da cui:
$$
Y(s) = G_1(s) \left( R(s) - Y_m(s) \right) = G_1(s) \left( R(s) - G_2(s)Y(s) \right)
$$
allora:
$$
Y(s) + G_1(s)G_2(s) Y(s) = G_1(s) R(s) \implies G(s) = \frac{G_1(s)}{1 + G_1(s) G_2(s)}
$$

\subsection{Raggiungibilità e osservabilità dei sistemi aggregati}
Vediamo come si valutano raggiungibilità e osservabilita nell'algebra dei blocchi, guardando ai diagrammi a blocchi.

\subsubsection{Oss. e ragg. della connessione in serie}
Abbiamo che la funzione di trasferimento di una connessione in serie sarà una forma:
$$
G(s) = G_1(s) G_2(s) = \frac{N_1(s)N_2(s)}{D_1(s)D_2(s)}
$$
dove gli $N_i$, $D_i$ sono numeratori e denominatori (uscite e ingressi) dellefunzioni di trasferimento $G_i$.

Possiamo sfruttare questo risultato per fare delle considerazioni su raggiungibilità e osservabilità. In particolare:
\begin{itemize}
	\item Se $N_1$ e $D_2$ hanno radici in comune, $G$ non è raggiungibile (\textbf{cancellazione zero-polo});
	\item Se $N_2$ e $D_1$ hanno radici in comune, $G$ non è osservabile (\textbf{cancellazione polo-zero}).
\end{itemize}

\subsubsection{Oss. e ragg. della connessione in parallelo}
Possiamo fare considerazioni simili sulla connessione in parallelo:
$$
G(s) = G_1(s) + G_2(s) = \frac{N_1(s)}{D_1(s)} + \frac{N_2(s)}{D_2(s)} = \frac{N_1(s)D_2(s) + N_2(s)D_1(s)}{D_1(s)D_2(s)}
$$

In questo caso, se $D_1$ e $D_2$ hanno radici comuni $G$ non è raggiungibile (i poli si sovrappongono). 

\subsubsection{Oss. e ragg. della connessione in retroazione}
Infine, vediamo il caso della connessione in retroazione:
$$
G(s) = \frac{\frac{N_1(s)}{D_1(s)}}{1 + \frac{N_1(s)}{D_1(s)} \frac{N_2(s)}{D_2(s)}} = \frac{N_1(s)D_2(s)}{D_1(s)D_2(s) + N_1(s)N_2(s)}
$$

Abbiamo quindi le regole relative alla connessione serie per il singolo prodotto $G_1 G_2$.
Le cancellazioni possono poi avvenire quando $N_1$ e $D_2$ hanno poli comuni.

Notiamo infine che la retroazione \textit{modifica i poli ma non gli zeri} del sistema in catena diretta, dove i \textbf{poli} sono le radici del \textit{denominatore} e gli \textbf{zeri} sono le radici del \textit{numeratore}.

\end{document}
